{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP N°2 : Natural Language Processing \n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 : Démontrez que les fonctions forward et backward se calculent bien ainsi \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le forward $\\alpha_{n+1}$ se déduit aisément du $\\alpha_n$ grâce aux probabilités en chaîne :\n",
    "<br/>\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\alpha_{x_{n+1}}(n+1) = p(x_{n+1}, y_{1:n+1})\n",
    "            &= \\sum_{x_n \\in \\Omega} p(x_{n+1},x_n, y_{1:n+1}) \\\\\n",
    "            &= \\sum_{x_n\\in \\Omega} p(y_{n+1}|x_{n+1}, x_n, y_{1:n})p(x_{n+1}, x_n, y_{1:n}) \\\\\n",
    "            &= p(y_{n+1}|x_{n+1}) \\sum_{x_n\\in \\Omega} p(x_{n+1}|x_n, y_{1:n})p(x_n, y_{1:n}) \\\\\n",
    "            &= p(y_{n+1}|x_{n+1}) \\sum_{x_n\\in \\Omega} p(x_{n+1} | x_n) \\alpha_{x_n}(n) \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "<br/>\n",
    "\n",
    "Quant au calcul du $\\beta_{n}$ en fonction du $\\beta_{n+1}$ cette fois-ci :\n",
    "<br/>\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\beta_{x_n}(n) = p(y_{n+1:N}|x_n) \n",
    "         &= \\sum_{x_{n+1}\\in \\Omega} p(y_{n+1:N}, x_{n+1}|x_n) \\\\\n",
    "         &= \\sum_{x_{n+1}\\in \\Omega} p(y_{n+2:N},y_{n+1}, x_{n+1}|x_n) \\\\\n",
    "         &= \\sum_{x_{n+1}\\in \\Omega} p(y_{n+2:N}|y_{n+1}, x_{n+1}, x_n)p(y_{n+1}, x_{n+1}|x_n) \\\\\n",
    "         &= \\sum_{x_{n+1}\\in \\Omega} p(y_{n+2:N}|y_{n+1}, x_{n+1}, x_n)p(y_{n+1}| x_{n+1},x_n)p(x_{n+1}|x_n) \\\\\n",
    "         &= \\sum_{x_{n+1}\\in \\Omega} p(y_{n+2:N}|x_{n+1})p(y_{n+1}|x_{n+1})p(x_{n+1}|x_n) \\\\\n",
    "         &= \\sum_{x_{n+1}\\in \\Omega} \\beta_{n+1}b_{x_{n+1}}(n+1)p(x_{n+1}|x_n) \\\\\n",
    "         &= \\sum_{x_{n+1}\\in \\Omega} \\beta_{x_{n+1}}(n+1)b_{x_{n+1}}(n+1)p(x_{n+1}|x_n) \\\\\n",
    "         \n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : *estimation* des paramètres de la chaîne de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1/ <br/>\n",
    "*Learning parameters* estime les trois paramètres de la chaîne de markov : $\\pi$, $A$ et $B$. <br/><br/>\n",
    "\n",
    "$Pi$ estime la probabilité qu'un mot donné soit un verbe par exemple, sans aucun conditionnement. On l'obtient facilement en l'estimant par la moyenne empirique. Pour cela, on compte le nombre d'apparition de chaque tag, et on divise par le nombre total de tag. <br/><br/>\n",
    "\n",
    "$A$ est une estimation de la matrice de transition. On se place dans le modèle Markovien, ainsi on va compter le nombre de transition d'un tag à un autre trouvées dans le texte. Concrétement, $A_{i,j}$ est égal au nombre de fois qu'on est passé du tag $j$ au tag $i$ divisé par le nombre d'apparition du tag $i$. <br/><br/>\n",
    "\n",
    "$B$ est une estimation de $p(Y_t = y | X_t = i)$ pour cela, on utilise encore a moyenne empirique. On compte combien de fois le mot $y$ est associé au tag $x$, puis on divise sur le nombre d'apparition du mot $y$.\n",
    "<br/><br/>\n",
    "\n",
    "2.2/ <br/>\n",
    "Les différents paramètres sont modélisés par des dictionnaires python et non par des tableaux. La raison à cela est que l'accès à une valeur dans un dictionnaire repose sur une table de hashage, et est donc beaucoup plus rapide que dans un tableau (accès dictionnaire en $O(1)$ contre $O(n^2)$ dans un tableau) <br/><br/>\n",
    "\n",
    "2.3/<br/>\n",
    "Cette estimation correspond à l'estimation des paramètres du maximum de vraisemmblance \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cf. les fonctions dans le dossier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/Alex2/Cours/2A/MA202/TP2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On éxécute les différents tests : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un fichier pour stocker les résultats :\n",
    "f = open(\"results.txt\",\"w\")\n",
    "f.write('') # On pense à le réinitialiser\n",
    "f.close()\n",
    "# Exécute les 6 programmes :\n",
    "r1 = open(\"HMC/Result_HMC/hmc_chunk_conll2000.py\", \"r\")\n",
    "exec(r1.read())\n",
    "r1.close()\n",
    "r2 = open(\"HMC/Result_HMC/hmc_chunk_conll2003.py\", \"r\")\n",
    "exec(r2.read())\n",
    "r2.close()\n",
    "r3 = open(\"HMC/Result_HMC/hmc_ner_conll2003.py\", \"r\")\n",
    "exec(r3.read())\n",
    "r3.close()\n",
    "r4 = open(\"HMC/Result_HMC/hmc_pos_conll2000.py\", \"r\")\n",
    "exec(r4.read())\n",
    "r4.close()\n",
    "r5 = open(\"HMC/Result_HMC/hmc_pos_conll2003.py\", \"r\")\n",
    "exec(r5.read())\n",
    "r5.close()\n",
    "r6 = open(\"HMC/Result_HMC/hmc_pos_ud_english.py\", \"r\")\n",
    "exec(r6.read())\n",
    "r6.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats moyens pour les 3 bases d'apprentissage : \n",
    "\n",
    "| | Chunk-Tagging | Pos-Tagging | NER-Tagging\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|taux d'erreur moyen | 6.40| 8.81| 37.59|\n",
    "| KW | 5.93| 4.04| 12.76|\n",
    "| UW |11.46| 56.76| 99.44|\n",
    "<br/> \n",
    "Les résultats sont plutôt satisfaisant pour le chunk tagging et le POS tagging. Bien que tous deux présentent des performances à peu près similaires sur les mots connus, c'est sur la segmentation des mots inconnus que les performances diffèrent. Le Chunk tagging est environ 5 fois plus performant sur les mots inconnus que le POS tagging, ce qui le rend plus robuste et explique donc une performance moyenne plus élevée qu'en POS tagging, bien que ce dernier soit plus performant sur les mots connus. <br/> \n",
    "Le *NER_tagging* présente des performances moindres à côté des précédents. <br/>  <br/> \n",
    "cependant pour les évaluer sur un même pied d'égalité, il faut considérer : \n",
    "<li/> La complexité de la segmentation effectuée\n",
    "<li/> Le mode d'évaluation du modèle <br/>  <br/> \n",
    "Les chunk et pos tagging sont évalués selon le pourcentage de mots bien labelisés, tandis que le NER tagging est évalué avec son score F1. <br/>\n",
    "De plus, la tâche confiée au NER tagging est plus subtile puisqu'un même mot rencontré dans un texte peut correspondre à plusieurs entités. Tandis qu'avec du chunk ou du POS, un mot a moins de labels possibles (par ex un verbe  ne peut correspondre qu'à un verbe, tands qu'un nom propre peut correspondre à une organisation, une personne, ...)\n",
    "<br/>\n",
    "Il faut aussi vérifier que les différentes méthodes ont eu la même quantité de données en apprentissage : \n",
    "<br/> \n",
    "\n",
    "| | CoNLL2000 | CoNLL2003 | UD English |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| Nb mots apprentissage | 220 661 | 219 552 | 217 128 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 :\n",
    "Dans nos calculs de forward et backward, nous sommes obligés de normaliser les termes, si on ne le fait pas, l'ordinateur va faire des erreurs d'arrondis causés par une limitation de la précision, ainsi on va se retrouver avec certains termes à 0 ou à 1 alors qu'ils ne devraient pas l'être et l'erreur va se propager et fausser l'ensemble. (On a une récurrence sur un très grand nombre de termes).\n",
    "<br/><br/>\n",
    "Cela n'affecte pas les résultats de notre algorithme. En effet, afin de déterminer $X_t$ à partir des observations $Y_{1:T}$, seul $\\Gamma$ nous intéresse\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\Gamma_i(t) = P(X_t=i | y_{1:T}) = \\frac{\\alpha_i(t)\\beta_i(t)}{\\sum_{j \\in \\Omega} \\alpha_j(t)\\beta_j(t)}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "<br/><br/>\n",
    "Les $\\alpha$ et $\\beta$ que nous avons calculé sont en réalité des $\\hat{\\alpha_i(t)}$ et $\\hat{\\beta_i(t)}$ où $\\hat{\\alpha_i(t)} = \\frac{\\alpha_i(t)}{\\sum_{j \\in \\Omega} \\alpha_j(t)}$ et $\\hat{\\beta_i(t)} = \\frac{\\beta_i(t)}{\\sum_{j \\in \\Omega} \\beta_j(t)}$\n",
    "<br/><br/>\n",
    "Quand on passe au calcul de notre $\\hat{\\Gamma}$ :\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\hat{\\Gamma_i(t)} = \\frac{ \\hat{\\alpha_i(t)} \\hat{\\beta_i(t)} }{\\sum_{j \\in \\Omega} \\hat{\\alpha_j(t)}\\hat{\\beta_j(t)}} \\\n",
    "&= \\frac{ \\frac{\\alpha_i(t)}{\\sum_{j \\in \\Omega} \\alpha_j(t)}\\frac{\\beta_i(t)}{\\sum_{j \\in \\Omega} \\beta_j(t)} }{\\sum_{j \\in \\Omega} \\frac{\\alpha_j(t)}{\\sum_{k \\in \\Omega} \\alpha_k(t)}\\frac{\\beta_j(t)}{\\sum_{k \\in \\Omega} \\beta_k(t)}} \\\\\n",
    "&= \\frac{\\alpha_i(t)\\beta_i(t)}{\\sum_{j \\in \\Omega} \\alpha_j(t)\\beta_j(t)} \\\\\n",
    "&= \\Gamma_i(t)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "Finalement, cette normalisation se compense dans le calcul de $\\Gamma$ !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le $epsilon$_$laplace$ (qui est choisi à $10^{-10}$ dans les algorithmes) permet d'éviter la division par zéro lorsque les probabilités deviennent très petites (erreurs de précision informatique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7 :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On crée un fichier pour stocker les résultats :\n",
    "f = open(\"results_down.txt\",\"w\")\n",
    "f.write('') # On pense à le réinitialiser\n",
    "f.close()\n",
    "# Exécute les 6 programmes :\n",
    "r1 = open(\"HMC/Result_HMC_Down/hmc_chunk_conll2000.py\", \"r\")\n",
    "exec(r1.read())\n",
    "r1.close()\n",
    "r2 = open(\"HMC/Result_HMC_Down/hmc_chunk_conll2003.py\", \"r\")\n",
    "exec(r2.read())\n",
    "r2.close()\n",
    "r3 = open(\"HMC/Result_HMC_Down/hmc_ner_conll2003.py\", \"r\")\n",
    "exec(r3.read())\n",
    "r3.close()\n",
    "r4 = open(\"HMC/Result_HMC_Down/hmc_pos_conll2000.py\", \"r\")\n",
    "exec(r4.read())\n",
    "r4.close()\n",
    "r5 = open(\"HMC/Result_HMC_Down/hmc_pos_conll2003.py\", \"r\")\n",
    "exec(r5.read())\n",
    "r5.close()\n",
    "r6 = open(\"HMC/Result_HMC_Down/hmc_pos_ud_english.py\", \"r\")\n",
    "exec(r6.read())\n",
    "r6.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats moyens pour les 3 bases d'apprentissage): \n",
    "\n",
    "| | Chunk-Tagging | Pos-Tagging | NER-Tagging\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Accuracy | 6.29| 6.22| 24.84|\n",
    "| KW | 5.93| 4.04| 12.76|\n",
    "| UW |10.18| 29.15| 55.71|\n",
    "<br/> \n",
    "\n",
    "## Résultats par base d'apprentissage : <br/>\n",
    "### CoNLL2000\n",
    "| | Chunk-Tagging | Pos-Tagging | NER-Tagging\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Accuracy | 7.08| 3.42| indisponible|\n",
    "| KW | 6.67| 1.93|indisponible |\n",
    "| UW |12.53| 23.34| indisponible|\n",
    "<br/> \n",
    "\n",
    "### CoNLL2003\n",
    "| | Chunk-Tagging | Pos-Tagging | NER-Tagging\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Accuracy | 5.50| 6.25|24.84 |\n",
    "| KW | 5.21| 4.03| 12.76|\n",
    "| UW |7.83| 23.82| 55.71|\n",
    "<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les résultats sont stockés dans un tableur joint au rendu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse des résultats : <br/>\n",
    "La variante Down améliore diminue le taux d'erreur de manière assez peu significative dans le cadre Chunk Tagging (0.1% de moins), de manière plus significative dans le cadre POS Tagging (2.6% de moins) mais de manière assez spectaculaire dans le cadre NER Tagging où l'on passe de 38% d'erreur à 25%. Cela s'explique assez aisément. La variante Down ne modifie le tagging seulement pour les mots inconnus. Comme montré dans les graphiques du pdf résultats, dans le cas des mots inconnus, le gain de performance est assez spectaculaire. Or ce sont les mots inconnus qui tirent nettement les résultats de NER Tagging vers le bas. On passe de 99.5% d'erreurs à 56% d'erreur pour le tag de mots inconnus. Ainsi, la variante Down s'attaque directement au défaut dans le cadre NER : la non robustesse aux mots inconnus. Le Chunk et POS Tagging s'avèrent eux plus robustes aux mots inconnus, même si, bien sûr, ils présentent de moins bons résultats que pour les mots connus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FWD-BWD Down Bis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est d'aller encore plus loin en apprenant des features supplémentaires (désormais on va également apprendre les mots avec les 3, 2, 1 voir 0 des derniers caractères)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "construct_train_set_features() takes 1 positional argument but 2 were given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b4c0ef1e52dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mr3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mr4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HMC/Result_HMC_Down_Bis/hmc_pos_conll2000.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mr4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mr5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HMC/Result_HMC_Down_Bis/hmc_pos_conll2003.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: construct_train_set_features() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "f = open(\"results_down_bis.txt\", \"w\")\n",
    "f.write(\"\")\n",
    "f.close()\n",
    "r1 = open(\"HMC/Result_HMC_Down_Bis/hmc_chunk_conll2000.py\", \"r\")\n",
    "exec(r1.read())\n",
    "r1.close()\n",
    "r2 = open(\"HMC/Result_HMC_Down_Bis/hmc_chunk_conll2003.py\", \"r\")\n",
    "exec(r2.read())\n",
    "r2.close()\n",
    "r3 = open(\"HMC/Result_HMC_Down_Bis/hmc_ner_conll2003.py\", \"r\")\n",
    "exec(r3.read())\n",
    "r3.close()\n",
    "r4 = open(\"HMC/Result_HMC_Down_Bis/hmc_pos_conll2000.py\", \"r\")\n",
    "exec(r4.read())\n",
    "r4.close()\n",
    "r5 = open(\"HMC/Result_HMC_Down_Bis/hmc_pos_conll2003.py\", \"r\")\n",
    "exec(r5.read())\n",
    "r5.close()\n",
    "r6 = open(\"HMC/Result_HMC_Down_Bis/hmc_pos_ud_english.py\", \"r\")\n",
    "exec(r6.read())\n",
    "r6.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les améliorations sont trop faibles pour être soulignées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthèse : \n",
    "Durant ce TP, nous avons mis en place une stratégie de segmentation de texte basé sur les chaînes de Markov cachées et estimateur bayésien MPM. Nous avons travaillé sur 3 types de lablélisations : les Chunk, POS et NER Tagging. <br/><br/>\n",
    "\n",
    "Le modèle CMC est un modèle très simplifié et cela lui confère de nombreux avantages : d'abord il est assez simple à implémenter et de plus, les lois marginales à postériori (que l'on doit calculer car à maximiser pour le MPM) est très efficace grâce aux algorithmes Forward et Backward. <br/><br/>\n",
    "\n",
    "Ce TP nous guide et nous fournit les principales fonctions pour mettre à bien cette stratégie. Un aspect sur lequel il est important de se pencher est la complexité algorithmique. Nous sommes dans un cas où le nombre de mots rencontré est très grand, ainsi il va être judicieux d'utiliser des dictionnaires python. En effet, les dictionnaires utilisent des indexations par clés qui, grâce à une table de hachage, nous mène directement aux bonnes adresses mémoires et évite de nombreuses boucles. La complexité en est fortement réduite et on le voit aux temps d'apprentissage (qui ne dépassent pas une ou deux secondes pour plus de 200 000 mots dans le pire des cas !) <br/><br/>\n",
    "\n",
    "Après avoir remarqué que le cas des mots inconnus était un réel frein à une bonne segmentation, il est proposé d'établir une nouvelle stratégie. On va augmenter le champs de nos connaissances en mots en autorisant l'apprentissage non pas de mots mais de features (moins d'information qu'un mot réel, par exmeple deux mots différents peuvent avoir les mêmes features). C'est une stratégie qui va donc prendre en compte la structure des mots (analyse des préfixes, nombre de lettres, ...) pour accroître le champ des connus. Cette stratégie est vraiment payante. Nous pouvons aussi remarquer que nous disposons de mots anglais, mais que cette stratégie s'appliquerait de la même manière à n'importe quelle langue (exception faite du choix des features qui dépend de la langue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats : \n",
    "Tous les résultats sont disponibles dans le pdf \"Résultats NLP\". On observe que certains problèmes sont par nature \"plus faciles\" : le POS Tagging est assez bien traité avec le modèle CMC puisque l'on obtient des erreurs qui tombent jusqu'à 3% environ. On remarque également des différences de robustesse face aux mots inconnus qui sont plutôt bien traités si l'on peut dire avec le POS Tagging (50% d'erreur) et très mal avec le NER Tagging (99,5% d'erreur !). Cela s'explique par le fait que tagger une entité (NER Tag) est une information \"plus fine\" que simplement assigner une fonction grammaticale, car il y a plus de nuances et l'apprentissage est plus long, nécessiterait plus de données car dès que l'on tombe sur un mot inconnu, il est impossible \"presque\" de trouver le bon label, même en connaissant les mots autour.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion : \n",
    "Les CMC apportent des perspectives très optimistes dans le NLP. Certains problèmes plus fins sont bien entendu plus sources d'erreurs. Les performances sont très sensibles à la dimension du set d'apprentissage car la robustesse aux mots inconnus est assez faible, et il est possible d'établir des stratégies de features extraction afin d'améliorer la segmentation. On peut assez logiquement imaginer que l'existence de différents langages (soutenu, familier, argot, ...) ne facilite pas la tâche. <br/>La stratégie \"Down\" apporte des résultats très puissant : un gain significatif de précision est apporté. On pourrait imaginer suivant le même modèle de nouvelles features dans le cadre de NER Tagging (comme la présence de symboles ($, €, ...), de lieux, de dates, ...)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda5f7fccd755a2421db3b6856ed80a36a3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}